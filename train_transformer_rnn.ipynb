{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8bb43f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tokenizers in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from -r requirements.txt (line 1)) (0.10.3)\n",
      "\u001b[33mWARNING: You are using pip version 21.1.2; however, version 21.1.3 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_latest_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2f016cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81b18c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk import sent_tokenize\n",
    "from tokenizers import Tokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7096312a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    'data/jd.csv', \n",
    "#     nrows=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4a5e1c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>FullDescription</th>\n",
       "      <th>LocationRaw</th>\n",
       "      <th>LocationNormalized</th>\n",
       "      <th>ContractType</th>\n",
       "      <th>ContractTime</th>\n",
       "      <th>Company</th>\n",
       "      <th>Category</th>\n",
       "      <th>SalaryRaw</th>\n",
       "      <th>SalaryNormalized</th>\n",
       "      <th>SourceName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12612628</td>\n",
       "      <td>Engineering Systems Analyst</td>\n",
       "      <td>Engineering Systems Analyst Dorking Surrey Sal...</td>\n",
       "      <td>Dorking, Surrey, Surrey</td>\n",
       "      <td>Dorking</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>20000 - 30000/annum 20-30K</td>\n",
       "      <td>25000</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12612830</td>\n",
       "      <td>Stress Engineer Glasgow</td>\n",
       "      <td>Stress Engineer Glasgow Salary **** to **** We...</td>\n",
       "      <td>Glasgow, Scotland, Scotland</td>\n",
       "      <td>Glasgow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>25000 - 35000/annum 25-35K</td>\n",
       "      <td>30000</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12612844</td>\n",
       "      <td>Modelling and simulation analyst</td>\n",
       "      <td>Mathematical Modeller / Simulation Analyst / O...</td>\n",
       "      <td>Hampshire, South East, South East</td>\n",
       "      <td>Hampshire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>20000 - 40000/annum 20-40K</td>\n",
       "      <td>30000</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12613049</td>\n",
       "      <td>Engineering Systems Analyst / Mathematical Mod...</td>\n",
       "      <td>Engineering Systems Analyst / Mathematical Mod...</td>\n",
       "      <td>Surrey, South East, South East</td>\n",
       "      <td>Surrey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>25000 - 30000/annum 25K-30K negotiable</td>\n",
       "      <td>27500</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12613647</td>\n",
       "      <td>Pioneer, Miser Engineering Systems Analyst</td>\n",
       "      <td>Pioneer, Miser  Engineering Systems Analyst Do...</td>\n",
       "      <td>Surrey, South East, South East</td>\n",
       "      <td>Surrey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>20000 - 30000/annum 20-30K</td>\n",
       "      <td>25000</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244763</th>\n",
       "      <td>72705211</td>\n",
       "      <td>TEACHER OF SCIENCE</td>\n",
       "      <td>Position: Qualified Teacher Subject/Specialism...</td>\n",
       "      <td>Swindon</td>\n",
       "      <td>Swindon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>contract</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Teaching Jobs</td>\n",
       "      <td>450 - 500 per week</td>\n",
       "      <td>22800</td>\n",
       "      <td>hays.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244764</th>\n",
       "      <td>72705212</td>\n",
       "      <td>TEACHER OF BUSINESS STUDIES AND ICT</td>\n",
       "      <td>Position: Qualified Teacher or NQT Subject/Spe...</td>\n",
       "      <td>Swindon</td>\n",
       "      <td>Swindon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>contract</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Teaching Jobs</td>\n",
       "      <td>450 - 500 per week</td>\n",
       "      <td>22800</td>\n",
       "      <td>hays.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244765</th>\n",
       "      <td>72705213</td>\n",
       "      <td>ENGLISH TEACHER</td>\n",
       "      <td>Position: Qualified Teacher Subject/Specialism...</td>\n",
       "      <td>Swindon</td>\n",
       "      <td>Swindon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>contract</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Teaching Jobs</td>\n",
       "      <td>450 - 500 per week</td>\n",
       "      <td>22800</td>\n",
       "      <td>hays.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244766</th>\n",
       "      <td>72705216</td>\n",
       "      <td>SUPPLY TEACHERS</td>\n",
       "      <td>Position: Qualified Teacher Subject/Specialism...</td>\n",
       "      <td>Wiltshire</td>\n",
       "      <td>Wiltshire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>contract</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Teaching Jobs</td>\n",
       "      <td>450 to 500 per week</td>\n",
       "      <td>22800</td>\n",
       "      <td>hays.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244767</th>\n",
       "      <td>72705235</td>\n",
       "      <td>Accountant</td>\n",
       "      <td>This entrepreneurial and growing private equit...</td>\n",
       "      <td>Hitchin</td>\n",
       "      <td>Hitchin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Teaching Jobs</td>\n",
       "      <td>40-45,000</td>\n",
       "      <td>42500</td>\n",
       "      <td>hays.co.uk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>244768 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Id                                              Title  \\\n",
       "0       12612628                        Engineering Systems Analyst   \n",
       "1       12612830                            Stress Engineer Glasgow   \n",
       "2       12612844                   Modelling and simulation analyst   \n",
       "3       12613049  Engineering Systems Analyst / Mathematical Mod...   \n",
       "4       12613647         Pioneer, Miser Engineering Systems Analyst   \n",
       "...          ...                                                ...   \n",
       "244763  72705211                                 TEACHER OF SCIENCE   \n",
       "244764  72705212                TEACHER OF BUSINESS STUDIES AND ICT   \n",
       "244765  72705213                                    ENGLISH TEACHER   \n",
       "244766  72705216                                    SUPPLY TEACHERS   \n",
       "244767  72705235                                         Accountant   \n",
       "\n",
       "                                          FullDescription  \\\n",
       "0       Engineering Systems Analyst Dorking Surrey Sal...   \n",
       "1       Stress Engineer Glasgow Salary **** to **** We...   \n",
       "2       Mathematical Modeller / Simulation Analyst / O...   \n",
       "3       Engineering Systems Analyst / Mathematical Mod...   \n",
       "4       Pioneer, Miser  Engineering Systems Analyst Do...   \n",
       "...                                                   ...   \n",
       "244763  Position: Qualified Teacher Subject/Specialism...   \n",
       "244764  Position: Qualified Teacher or NQT Subject/Spe...   \n",
       "244765  Position: Qualified Teacher Subject/Specialism...   \n",
       "244766  Position: Qualified Teacher Subject/Specialism...   \n",
       "244767  This entrepreneurial and growing private equit...   \n",
       "\n",
       "                              LocationRaw LocationNormalized ContractType  \\\n",
       "0                 Dorking, Surrey, Surrey            Dorking          NaN   \n",
       "1             Glasgow, Scotland, Scotland            Glasgow          NaN   \n",
       "2       Hampshire, South East, South East          Hampshire          NaN   \n",
       "3          Surrey, South East, South East             Surrey          NaN   \n",
       "4          Surrey, South East, South East             Surrey          NaN   \n",
       "...                                   ...                ...          ...   \n",
       "244763                            Swindon            Swindon          NaN   \n",
       "244764                            Swindon            Swindon          NaN   \n",
       "244765                            Swindon            Swindon          NaN   \n",
       "244766                          Wiltshire          Wiltshire          NaN   \n",
       "244767                            Hitchin            Hitchin          NaN   \n",
       "\n",
       "       ContractTime                       Company          Category  \\\n",
       "0         permanent  Gregory Martin International  Engineering Jobs   \n",
       "1         permanent  Gregory Martin International  Engineering Jobs   \n",
       "2         permanent  Gregory Martin International  Engineering Jobs   \n",
       "3         permanent  Gregory Martin International  Engineering Jobs   \n",
       "4         permanent  Gregory Martin International  Engineering Jobs   \n",
       "...             ...                           ...               ...   \n",
       "244763     contract                           NaN     Teaching Jobs   \n",
       "244764     contract                           NaN     Teaching Jobs   \n",
       "244765     contract                           NaN     Teaching Jobs   \n",
       "244766     contract                           NaN     Teaching Jobs   \n",
       "244767    permanent                           NaN     Teaching Jobs   \n",
       "\n",
       "                                     SalaryRaw  SalaryNormalized  \\\n",
       "0                   20000 - 30000/annum 20-30K             25000   \n",
       "1                   25000 - 35000/annum 25-35K             30000   \n",
       "2                   20000 - 40000/annum 20-40K             30000   \n",
       "3       25000 - 30000/annum 25K-30K negotiable             27500   \n",
       "4                   20000 - 30000/annum 20-30K             25000   \n",
       "...                                        ...               ...   \n",
       "244763                      450 - 500 per week             22800   \n",
       "244764                      450 - 500 per week             22800   \n",
       "244765                      450 - 500 per week             22800   \n",
       "244766                     450 to 500 per week             22800   \n",
       "244767                               40-45,000             42500   \n",
       "\n",
       "              SourceName  \n",
       "0       cv-library.co.uk  \n",
       "1       cv-library.co.uk  \n",
       "2       cv-library.co.uk  \n",
       "3       cv-library.co.uk  \n",
       "4       cv-library.co.uk  \n",
       "...                  ...  \n",
       "244763        hays.co.uk  \n",
       "244764        hays.co.uk  \n",
       "244765        hays.co.uk  \n",
       "244766        hays.co.uk  \n",
       "244767        hays.co.uk  \n",
       "\n",
       "[244768 rows x 12 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56ab8782",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer.from_file(\"data/jd_tokenizer_wordpiece.json\")\n",
    "tokenizer.enable_padding()\n",
    "tokenizer.enable_truncation(512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53bffb3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Encoding(num_tokens=3, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]),\n",
       " Encoding(num_tokens=3, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode_batch(['small sent', 'a larger sent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14490bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from src.utils import DataCollatorForLanguageModeling, LineByLineDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c4f5bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = DataCollatorForLanguageModeling(tokenizer, mlm_probability=0.2)\n",
    "lblg = LineByLineDataGenerator(tokenizer, dc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8613c156",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0a22906",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.layers import SelfAttentionLayer, EncoderBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42bbc709",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerRnn_MLM(nn.Module):\n",
    "    def __init__(self,tokenizer=None, emb_dimension=512, n_head=8, dropout=0.1, n_layers=6):\n",
    "        super().__init__()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.token_encoder = nn.Embedding(tokenizer.get_vocab_size(), emb_dimension)\n",
    "        self.position_encoder = nn.LSTM(emb_dimension, emb_dimension, batch_first=True)\n",
    "        \n",
    "        \n",
    "        self.encoders = nn.ModuleList([EncoderBlock(emb_dimension, n_head, dropout) for _ in range(n_layers)])\n",
    "        self.lm_head = nn.Linear(emb_dimension, tokenizer.get_vocab_size())\n",
    "        \n",
    "    def forward(self, x, mask=None):\n",
    "        B, T = x.shape\n",
    "        x_tok = self.token_encoder(x)\n",
    "        \n",
    "        x_emb, _ = self.position_encoder(x_tok)\n",
    "        \n",
    "        for block in self.encoders:\n",
    "            x_emb = block(x_emb, mask)\n",
    "            \n",
    "        out = self.lm_head(x_emb)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8bd9815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerRnn_MLM(\n",
       "  (token_encoder): Embedding(36000, 512)\n",
       "  (position_encoder): LSTM(512, 512, batch_first=True)\n",
       "  (encoders): ModuleList(\n",
       "    (0): EncoderBlock(\n",
       "      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (self_attention): SelfAttentionLayer(\n",
       "        (qw): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (kw): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (vw): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "      (feed_forward): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (1): GELU()\n",
       "        (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): EncoderBlock(\n",
       "      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (self_attention): SelfAttentionLayer(\n",
       "        (qw): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (kw): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (vw): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "      (feed_forward): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (1): GELU()\n",
       "        (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (2): EncoderBlock(\n",
       "      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (self_attention): SelfAttentionLayer(\n",
       "        (qw): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (kw): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (vw): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "      (feed_forward): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (1): GELU()\n",
       "        (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (3): EncoderBlock(\n",
       "      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (self_attention): SelfAttentionLayer(\n",
       "        (qw): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (kw): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (vw): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "      (feed_forward): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (1): GELU()\n",
       "        (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (4): EncoderBlock(\n",
       "      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (self_attention): SelfAttentionLayer(\n",
       "        (qw): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (kw): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (vw): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "      (feed_forward): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (1): GELU()\n",
       "        (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (5): EncoderBlock(\n",
       "      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (self_attention): SelfAttentionLayer(\n",
       "        (qw): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (kw): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (vw): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "      (feed_forward): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (1): GELU()\n",
       "        (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=36000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_model = TransformerRnn_MLM(tokenizer)\n",
    "transformer_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d31d549b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(transformer_model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "698009d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_loss = 0.0\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84e0cdef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[220, 118]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"thiss\").ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b5662e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this ##s'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([220, 118])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69e5b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss at 0 is 1.0619625091552736\n",
      "Running loss at 25 is 14.966107193772396\n",
      "Running loss at 50 is 13.288137882227167\n",
      "Running loss at 75 is 10.925760078568782\n",
      "Running loss at 100 is 8.682759937149376\n",
      "Running loss at 125 is 7.575017956228935\n",
      "Running loss at 150 is 7.237727565051257\n",
      "Running loss at 175 is 7.015189010476763\n",
      "Running loss at 200 is 6.898986802592382\n",
      "Running loss at 225 is 6.749683723556738\n",
      "Running loss at 250 is 6.813427401607177\n",
      "Running loss at 275 is 6.722978825673257\n",
      "Running loss at 300 is 6.772609074445519\n",
      "Running loss at 325 is 6.746997588480182\n",
      "Running loss at 350 is 6.6096184271641905\n",
      "Running loss at 375 is 6.5720613370541425\n",
      "Running loss at 400 is 6.630730843624689\n",
      "Running loss at 425 is 6.678305857348106\n",
      "Running loss at 450 is 6.6015687558983505\n",
      "Running loss at 475 is 6.606638294943304\n",
      "Running loss at 500 is 6.457502405577634\n",
      "Running loss at 525 is 6.541095737229037\n",
      "Running loss at 550 is 6.464594528249783\n",
      "Running loss at 575 is 6.3027569275530055\n",
      "Running loss at 600 is 6.387645789343542\n",
      "Running loss at 625 is 6.435496840939376\n",
      "Running loss at 650 is 6.303953852612308\n",
      "Running loss at 675 is 6.229988616492\n",
      "Running loss at 700 is 6.214792908638696\n",
      "Running loss at 725 is 6.23231415196251\n",
      "Running loss at 750 is 6.235806607025031\n",
      "Running loss at 775 is 6.150000379175763\n",
      "Running loss at 800 is 6.1740366976526255\n",
      "Running loss at 825 is 6.106736334324053\n",
      "Running loss at 850 is 6.057503394012565\n",
      "Running loss at 875 is 6.139964231923006\n",
      "Running loss at 900 is 5.967121749741162\n",
      "Running loss at 925 is 6.0298812719143715\n",
      "Running loss at 950 is 5.964814909569032\n",
      "Running loss at 975 is 5.8820910429968585\n",
      "Running loss at 1000 is 5.944911853323511\n",
      "Running loss at 1025 is 5.948343813577704\n",
      "Running loss at 1050 is 6.018131721816611\n",
      "Running loss at 1075 is 5.978448520678178\n",
      "Running loss at 1100 is 6.012969887812421\n",
      "Running loss at 1125 is 5.813822939559459\n",
      "Running loss at 1150 is 5.764220620711868\n",
      "Running loss at 1175 is 5.73706257199084\n",
      "Running loss at 1200 is 5.743705272850435\n",
      "Running loss at 1225 is 5.7274154971914255\n",
      "Running loss at 1250 is 5.739064406449632\n",
      "Running loss at 1275 is 5.624084940733772\n",
      "Running loss at 1300 is 5.641103383383076\n",
      "Running loss at 1325 is 5.540013926548194\n",
      "Running loss at 1350 is 5.504363059673627\n",
      "Running loss at 1375 is 5.619055212336461\n",
      "Running loss at 1400 is 5.642022811188294\n",
      "Running loss at 1425 is 5.501673721239613\n",
      "Running loss at 1450 is 5.4850048069474635\n",
      "Running loss at 1475 is 5.54785866864346\n",
      "Running loss at 1500 is 5.588046841463051\n",
      "Running loss at 1525 is 5.570743602336611\n",
      "Running loss at 1550 is 5.588568847249651\n",
      "Running loss at 1575 is 5.358054912059816\n",
      "Running loss at 1600 is 5.414749712477667\n",
      "Running loss at 1625 is 5.605077574441948\n",
      "Running loss at 1650 is 5.350603487983123\n",
      "Running loss at 1675 is 5.416825252060924\n",
      "Running loss at 1700 is 5.281523798658148\n",
      "Running loss at 1725 is 5.341075548644482\n",
      "Running loss at 1750 is 5.467118903148362\n",
      "Running loss at 1775 is 5.345668974051857\n",
      "Running loss at 1800 is 5.291490064032253\n",
      "Running loss at 1825 is 5.424241274064172\n",
      "Running loss at 1850 is 5.342967757850201\n",
      "Running loss at 1875 is 5.419538804558667\n",
      "Running loss at 1900 is 5.36723604618321\n",
      "Running loss at 1925 is 5.296156386127132\n",
      "Running loss at 1950 is 5.2546357960034245\n",
      "Running loss at 1975 is 5.323527779042789\n",
      "Running loss at 2000 is 5.351502995648429\n",
      "Running loss at 2025 is 5.284712747713211\n",
      "Running loss at 2050 is 5.182750836530217\n",
      "Running loss at 2075 is 5.110960759572788\n",
      "Running loss at 2100 is 5.223289723651482\n",
      "Running loss at 2125 is 5.283446702070342\n",
      "Running loss at 2150 is 5.214255954303717\n",
      "Running loss at 2175 is 5.224441850136321\n",
      "Running loss at 2200 is 5.292343882904458\n",
      "Running loss at 2225 is 5.250037760818247\n",
      "Running loss at 2250 is 5.330787160057368\n",
      "Running loss at 2275 is 5.290068804355605\n",
      "Running loss at 2300 is 5.074031660480139\n",
      "Running loss at 2325 is 5.1983973347180426\n",
      "Running loss at 2350 is 5.116451489119221\n",
      "Running loss at 2375 is 5.203791278364695\n",
      "Running loss at 2400 is 5.243702165984687\n",
      "Running loss at 2425 is 5.120416385629971\n",
      "Running loss at 2450 is 5.139419253781406\n",
      "Running loss at 2475 is 5.089111574716616\n",
      "Running loss at 2500 is 4.951069816356512\n",
      "Running loss at 2525 is 5.070842277690451\n",
      "Running loss at 2550 is 5.197791291858283\n",
      "Running loss at 2575 is 5.024989552118861\n",
      "Running loss at 2600 is 5.110621535433333\n",
      "Running loss at 2625 is 5.157702113769147\n",
      "Running loss at 2650 is 5.085253434600835\n",
      "Running loss at 2675 is 5.07415651952991\n",
      "Running loss at 2700 is 4.994823137063505\n",
      "Running loss at 2725 is 5.067885641695606\n",
      "Running loss at 2750 is 4.874447253180454\n",
      "Running loss at 2775 is 5.041352766276589\n",
      "Running loss at 2800 is 4.798451666612467\n",
      "Running loss at 2825 is 4.737477241839877\n",
      "Running loss at 2850 is 4.9134003692554975\n",
      "Running loss at 2875 is 4.9907596169424036\n",
      "Running loss at 2900 is 4.952281208932143\n",
      "Running loss at 2925 is 4.921831449833708\n",
      "Running loss at 2950 is 4.712055301097342\n",
      "Running loss at 2975 is 5.083280329265886\n",
      "Running loss at 3000 is 5.019801174689652\n",
      "Running loss at 3025 is 4.842622922479925\n",
      "Running loss at 3050 is 4.815874966722157\n",
      "Running loss at 3075 is 4.903487476649367\n",
      "Running loss at 3100 is 4.7957063328387255\n",
      "Running loss at 3125 is 4.647592372376406\n",
      "Running loss at 3150 is 4.783431182590329\n",
      "Running loss at 3175 is 4.664897263391592\n",
      "Running loss at 3200 is 4.722906273041583\n",
      "Running loss at 3225 is 4.644449433596103\n",
      "Running loss at 3250 is 4.503200349702335\n",
      "Running loss at 3275 is 4.787763915770752\n",
      "Running loss at 3300 is 4.594160085093089\n",
      "Running loss at 3325 is 4.638297473179481\n",
      "Running loss at 3350 is 4.670603410951605\n",
      "Running loss at 3375 is 4.741451942324506\n",
      "Running loss at 3400 is 4.572081824092904\n",
      "Running loss at 3425 is 4.583279724829284\n",
      "Running loss at 3450 is 4.381066735430413\n",
      "Running loss at 3475 is 4.730797507287111\n",
      "Running loss at 3500 is 4.615452140819999\n",
      "Running loss at 3525 is 4.703789920722945\n",
      "Running loss at 3550 is 4.680919767426988\n",
      "Running loss at 3575 is 4.588761717888826\n",
      "Running loss at 3600 is 4.41023752644201\n",
      "Running loss at 3625 is 4.518753474555652\n",
      "Running loss at 3650 is 4.471027602146931\n",
      "Running loss at 3675 is 4.5034615422008875\n",
      "Running loss at 3700 is 4.615809805774187\n",
      "Running loss at 3725 is 4.602429650247116\n",
      "Running loss at 3750 is 4.410301076246711\n",
      "Running loss at 3775 is 4.2774283411423\n",
      "Running loss at 3800 is 4.473041534007764\n",
      "Running loss at 3825 is 4.406700256794419\n",
      "Running loss at 3850 is 4.392851942669505\n",
      "Running loss at 3875 is 4.4292309862822705\n",
      "Running loss at 3900 is 4.382355285535345\n",
      "Running loss at 3925 is 4.202098872014882\n",
      "Running loss at 3950 is 4.4511042740709605\n",
      "Running loss at 3975 is 4.441897332692271\n",
      "Running loss at 4000 is 4.54418941423895\n",
      "Running loss at 4025 is 4.474819680208019\n",
      "Running loss at 4050 is 4.278312928275994\n",
      "Running loss at 4075 is 4.266627039942608\n",
      "Running loss at 4100 is 4.288956525670343\n",
      "Running loss at 4125 is 4.295028195974042\n",
      "Running loss at 4150 is 4.327427277373716\n",
      "Running loss at 4175 is 4.3197865529087744\n",
      "Running loss at 4200 is 4.507588444950976\n",
      "Running loss at 4225 is 4.237592391968984\n",
      "Running loss at 4250 is 4.270526420548519\n",
      "Running loss at 4275 is 4.193133888859867\n",
      "Running loss at 4300 is 4.239515922782392\n",
      "Running loss at 4325 is 4.164557859201439\n",
      "Running loss at 4350 is 4.373476641080725\n",
      "Running loss at 4375 is 4.541881732269599\n",
      "Running loss at 4400 is 4.41406201882666\n",
      "Running loss at 4425 is 4.229309873580531\n",
      "Running loss at 4450 is 4.214444217995108\n",
      "Running loss at 4475 is 4.407808573074116\n",
      "Running loss at 4500 is 4.349879952310015\n",
      "Running loss at 4525 is 4.241561631265936\n",
      "Running loss at 4550 is 4.238829079858391\n",
      "Running loss at 4575 is 4.1543839940479526\n",
      "Running loss at 4600 is 4.23385911802818\n",
      "Running loss at 4625 is 4.190947386290769\n",
      "Running loss at 4650 is 4.174364328971366\n",
      "Running loss at 4675 is 4.376028776085008\n",
      "Running loss at 4700 is 4.351373040267636\n",
      "Running loss at 4725 is 4.330365819857886\n",
      "Running loss at 4750 is 4.259236299138456\n",
      "Running loss at 4775 is 4.126524454534222\n",
      "Running loss at 4825 is 4.416309230654752\n",
      "Running loss at 4850 is 4.080275650253798\n",
      "Running loss at 4875 is 4.121521424270638\n",
      "Running loss at 6800 is 3.9264525718171215\n",
      "Running loss at 6825 is 3.934791115915724\n",
      "Running loss at 6850 is 3.971188469291517\n",
      "Running loss at 6875 is 4.069109534754826\n",
      "Running loss at 6900 is 3.944915622453269\n",
      "Running loss at 6925 is 3.8164019755529193\n",
      "Running loss at 6950 is 3.788787308466916\n",
      "Running loss at 6975 is 3.7970277734535625\n",
      "Running loss at 7000 is 3.9731866723647413\n",
      "Running loss at 7025 is 3.796120974344534\n",
      "Running loss at 7050 is 3.8806760662956163\n",
      "Running loss at 7075 is 3.8666376482666993\n",
      "Running loss at 7100 is 3.975674141206842\n",
      "Running loss at 7125 is 3.719880133617224\n",
      "Running loss at 7150 is 3.8503492564037862\n",
      "Running loss at 7175 is 3.8770335383567183\n",
      "Running loss at 7200 is 3.814348491228143\n",
      "Running loss at 7225 is 3.663090325990108\n",
      "Running loss at 7250 is 3.6681039825755075\n",
      "Running loss at 7275 is 3.8547469395822653\n",
      "Running loss at 7300 is 3.78196868032275\n",
      "Running loss at 7325 is 3.707668830917725\n",
      "Running loss at 7350 is 3.917191604457587\n",
      "Running loss at 7375 is 3.7874333698367204\n",
      "Running loss at 7400 is 3.774721515274828\n",
      "Running loss at 7425 is 3.8768064850995696\n",
      "Running loss at 7450 is 4.030642722670131\n",
      "Running loss at 7475 is 3.7472206628515394\n",
      "Running loss at 7525 is 3.606638382788072\n",
      "Running loss at 7550 is 3.688474435096337\n",
      "Running loss at 7575 is 3.58107416985665\n",
      "Running loss at 14175 is 3.2048544342150893\n",
      "Running loss at 14200 is 3.3289657359692533\n",
      "Running loss at 14225 is 3.3092976302402097\n",
      "Running loss at 14250 is 3.3215046109723656\n",
      "Running loss at 14275 is 3.3281789008881604\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-9fb0c957c5ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0maccumulation_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0maccumulation_steps\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "accumulation_steps = 8\n",
    "transformer_model.train()\n",
    "for index, batch in enumerate(lblg.generate(df.FullDescription.sample(frac=1.0), batch_size=8, max_length=128)):\n",
    "    if index > 50000:\n",
    "        break\n",
    "\n",
    "    inp = batch['input_ids'].to(device)\n",
    "    labels = batch['labels'].to(device)\n",
    "    \n",
    "    output = transformer_model(inp)\n",
    "    output_shape = output.shape\n",
    "    loss_all = F.cross_entropy(output.view(-1, output_shape[-1]), labels.view(-1), reduction='none')\n",
    "    loss = loss_all[loss_all > 0].mean()\n",
    "    lit = loss.item()\n",
    "    losses.append(lit)\n",
    "    running_loss = 0.9 * running_loss + 0.1 * lit\n",
    "    if index % 25 == 0:\n",
    "        print(f'Running loss at {index} is {running_loss}')\n",
    "    \n",
    "    loss = loss / accumulation_steps\n",
    "    loss.backward()\n",
    "    if (index+1) % accumulation_steps == 0:  \n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f7eba835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(220, device='cuda:0')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(loss_all > 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca05fa32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.sort(\n",
       "values=tensor([1.1921e-07, 6.1989e-06, 1.2398e-05, 1.9193e-05, 2.0861e-05, 2.2053e-05,\n",
       "        2.3126e-05, 5.0901e-05, 5.1497e-05, 5.4596e-05, 2.0323e-04, 4.0428e-04,\n",
       "        4.1047e-04, 4.1512e-04, 5.9587e-04, 6.0254e-04, 7.1381e-04, 8.3662e-04,\n",
       "        2.0119e-03, 3.0483e-03, 3.2293e-03, 6.1741e-03, 8.9698e-03, 1.1048e-02,\n",
       "        1.2968e-02, 1.5509e-02, 1.8543e-02, 2.0435e-02, 2.6774e-02, 4.8169e-02,\n",
       "        5.8932e-02, 6.2731e-02, 6.4784e-02, 6.9545e-02, 7.5172e-02, 8.9313e-02,\n",
       "        1.0246e-01, 1.0327e-01, 1.1305e-01, 1.2961e-01, 1.3194e-01, 1.4465e-01,\n",
       "        1.5520e-01, 1.9256e-01, 2.0288e-01, 2.1338e-01, 2.3072e-01, 3.4234e-01,\n",
       "        3.4329e-01, 3.8262e-01, 4.1821e-01, 4.2969e-01, 4.3794e-01, 4.5663e-01,\n",
       "        4.9053e-01, 5.0722e-01, 5.5622e-01, 5.6588e-01, 5.8483e-01, 5.9207e-01,\n",
       "        6.2594e-01, 6.3632e-01, 6.5810e-01, 6.9409e-01, 7.5152e-01, 7.9761e-01,\n",
       "        8.0282e-01, 8.3105e-01, 9.2402e-01, 9.5093e-01, 1.2428e+00, 1.2509e+00,\n",
       "        1.2569e+00, 1.2764e+00, 1.3373e+00, 1.5055e+00, 1.6526e+00, 1.7097e+00,\n",
       "        1.8644e+00, 1.9591e+00, 2.0122e+00, 2.0520e+00, 2.0677e+00, 2.1471e+00,\n",
       "        2.1937e+00, 2.2743e+00, 2.2772e+00, 2.2975e+00, 2.2984e+00, 2.3266e+00,\n",
       "        2.3570e+00, 2.3786e+00, 2.3981e+00, 2.4427e+00, 2.5053e+00, 2.5390e+00,\n",
       "        2.5451e+00, 2.5593e+00, 2.6170e+00, 2.7091e+00, 2.8821e+00, 2.9139e+00,\n",
       "        2.9695e+00, 2.9703e+00, 3.0703e+00, 3.0961e+00, 3.1294e+00, 3.1630e+00,\n",
       "        3.1635e+00, 3.2456e+00, 3.2726e+00, 3.4816e+00, 3.5701e+00, 3.5928e+00,\n",
       "        3.6198e+00, 3.6781e+00, 3.8440e+00, 3.8886e+00, 3.9063e+00, 3.9373e+00,\n",
       "        4.0012e+00, 4.0106e+00, 4.0487e+00, 4.0919e+00, 4.2986e+00, 4.3045e+00,\n",
       "        4.3568e+00, 4.4525e+00, 4.4598e+00, 4.4950e+00, 4.5313e+00, 4.5328e+00,\n",
       "        4.5373e+00, 4.5473e+00, 4.5559e+00, 4.5695e+00, 4.6078e+00, 4.6657e+00,\n",
       "        4.7077e+00, 4.7581e+00, 4.8115e+00, 4.8461e+00, 4.9084e+00, 5.0649e+00,\n",
       "        5.0961e+00, 5.1685e+00, 5.3427e+00, 5.3712e+00, 5.4339e+00, 5.5320e+00,\n",
       "        5.5965e+00, 5.7017e+00, 5.8240e+00, 5.9143e+00, 5.9393e+00, 5.9639e+00,\n",
       "        5.9753e+00, 5.9793e+00, 6.1028e+00, 6.1408e+00, 6.1938e+00, 6.2887e+00,\n",
       "        6.3218e+00, 6.3942e+00, 6.4308e+00, 6.6104e+00, 6.7360e+00, 6.7799e+00,\n",
       "        6.8523e+00, 6.9168e+00, 6.9216e+00, 7.0338e+00, 7.0956e+00, 7.1131e+00,\n",
       "        7.1824e+00, 7.1862e+00, 7.1907e+00, 7.3161e+00, 7.5212e+00, 7.5220e+00,\n",
       "        7.5595e+00, 7.6063e+00, 7.7158e+00, 8.1476e+00, 8.1755e+00, 8.2097e+00,\n",
       "        8.3549e+00, 8.4945e+00, 8.5774e+00, 8.5816e+00, 8.8109e+00, 8.8221e+00,\n",
       "        8.9091e+00, 9.3931e+00, 9.6260e+00, 9.6920e+00, 9.7212e+00, 9.7618e+00,\n",
       "        9.8126e+00, 9.8461e+00, 9.8587e+00, 1.0010e+01, 1.0117e+01, 1.0139e+01,\n",
       "        1.0414e+01, 1.0757e+01, 1.0962e+01, 1.0983e+01, 1.1058e+01, 1.1593e+01,\n",
       "        1.2605e+01, 1.2687e+01, 1.3532e+01, 1.4327e+01, 1.4347e+01],\n",
       "       device='cuda:0', grad_fn=<SortBackward>),\n",
       "indices=tensor([ 84,  64,  28,  96, 154,  67, 155, 208,  10,  75, 168,   8, 131,  71,\n",
       "         87, 137,  43, 209,  88, 210,  69,  77, 127,  14, 142, 181, 148,  53,\n",
       "         63,  85, 132, 189,  79, 203, 105,   1, 207, 112, 106, 184,  70, 170,\n",
       "        174, 100, 190, 180,  51, 179, 204, 183, 123, 128, 129, 199,  25, 166,\n",
       "         68, 205,  16, 130,  21,  17, 185, 206, 202,   0, 158, 140, 138,  15,\n",
       "        125, 182,  66,  40, 147, 116, 120,  52,  18,  50,  54,  31, 214,  44,\n",
       "        110, 192,  41,  74,  61,  34,  47,  26,  29,  92, 146, 178, 193,  76,\n",
       "         95, 143, 177, 101,  30,   9, 135,  20,  39, 118,  98,  62,   6, 173,\n",
       "        119,  13,  60,  83,   2,  37, 161, 102, 201, 167, 187, 122,  81,  24,\n",
       "         19,  89,  36, 200, 124, 144,  45, 141, 107, 149,  42, 139,  12,  82,\n",
       "        121, 169,  78, 175,  58, 191,  97,  93,  38,  80,  73, 103,  56,  27,\n",
       "        194, 186, 198, 172,  57,  32, 117, 104, 111,  22,  55,  48,  49, 196,\n",
       "          3, 115, 176,  90,  46,   4, 197,  65, 126, 162,  59, 133,  35, 108,\n",
       "        109, 114, 151, 145,   5, 188, 136,  94, 113,  99, 150, 164, 152, 195,\n",
       "         23, 134, 153, 160, 213,   7, 159,  33,  91, 211, 171, 163, 212,  86,\n",
       "         72, 156,  11, 157, 165], device='cuda:0'))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_all[loss_all>0].sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32cd2fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, PATH):\n",
    "    torch.save(model.state_dict(), PATH)\n",
    "    \n",
    "def load_model(PATH):\n",
    "    model = RNN_MLM(tokenizer)\n",
    "    model.load_state_dict(torch.load(PATH, map_location=device))\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "73f9601e",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(transformer_model, 'models/transformer_rnn_6_512_bi_wordpiece.pt')\n",
    "# rnn_mlm_model = load_model('models/rnn_4_bi_wordpiece.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6e4ef6d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4835, device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9fc01d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a129f5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9367d608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from plotly.offline import init_notebook_mode\n",
    "init_notebook_mode(connected=True)\n",
    "from plotly import express as px\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad869196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ls = pd.Series(losses)\n",
    "ls.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e6cce83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/seaborn/_decorators.py:43: FutureWarning:\n",
      "\n",
      "Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "\n",
      "/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1370: RuntimeWarning:\n",
      "\n",
      "All-NaN slice encountered\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.lineplot(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "aef59e72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer_MLM(\n",
       "  (token_encoder): Embedding(36000, 512)\n",
       "  (encoders): ModuleList(\n",
       "    (0): EncoderBlock(\n",
       "      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (self_attention): SelfAttentionLayer(\n",
       "        (qw): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (kw): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (vw): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "      (feed_forward): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (1): GELU()\n",
       "        (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): EncoderBlock(\n",
       "      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (self_attention): SelfAttentionLayer(\n",
       "        (qw): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (kw): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (vw): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "      (feed_forward): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (1): GELU()\n",
       "        (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (2): EncoderBlock(\n",
       "      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (self_attention): SelfAttentionLayer(\n",
       "        (qw): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (kw): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (vw): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "      (feed_forward): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (1): GELU()\n",
       "        (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (3): EncoderBlock(\n",
       "      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (self_attention): SelfAttentionLayer(\n",
       "        (qw): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (kw): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (vw): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "      (feed_forward): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (1): GELU()\n",
       "        (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (4): EncoderBlock(\n",
       "      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (self_attention): SelfAttentionLayer(\n",
       "        (qw): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (kw): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (vw): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "      (feed_forward): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (1): GELU()\n",
       "        (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (5): EncoderBlock(\n",
       "      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (self_attention): SelfAttentionLayer(\n",
       "        (qw): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (kw): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (vw): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "      (feed_forward): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (1): GELU()\n",
       "        (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=36000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e5458751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C Developer Belfast Salary up to ****k pa Our client, a leading edge Software Development Centre in Belfast requires C Developers to deliver key software products directly for their clients and for their business teams using the latest Microsoft technologies (.NET C, ASP.NET and SQL Server). Key Accountabilities â€¢ Design and develop cuttingedge software solutions, developed in C .Net with SQL as the back end data store. â€¢ Ensure all deliverables for projects are completed on time, to budget and within quality standards. â€¢ Assist the Project Manager in production of estimates for development activity. â€¢ Work with the Business and Data Analysts to drive the requirements forward. â€¢ Provide support and consultancy across all test phases of the project. â€¢ Participation in planning of software releases, their execution and postrelease activities. â€¢ Assist with maintenance and production support. â€¢ Support colleagues through advice and technical assistance. Key Technical Skills â€¢ A degree in IT or related subject and at least 2 years recent relevant experience in .NET software development within a commercial environment. â€¢ Technically excellent in C, ASP.NET, MVC, web development using Visual Studio, also strong working knowledge of SQL Server and TFS. â€¢ Experience of full software lifecycle and different methodologies. â€¢ Working knowledge of design patterns and practices. â€¢ Excellent time management skills and the proven ability and drive to meet deadlines. â€¢ Excellent teamworking skills, ability to work independently, show ownership and commitment to the success of the team. â€¢ Proven problem solving skills, analytical mind and a keen eye for detail. Hours of work: Core hours are 8am to 6pm Monday to Friday and you will be required to work 37.5 hours per week, timings will be agreed with your manager. Recruitment Direct is acting as a recruitment agency'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.Title.notnull() & df.Title.str.contains('Software Developer')].iloc[0]['FullDescription']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b560a3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "para = \"\"\"Designation: Python Distributed [MASK] Engineer\n",
    "Educational Qualifications: B.Tech/M.Tech/MS/MCA\n",
    "Experience: 3-9 Years\n",
    "What you will do\n",
    "Apply your [MASK] set to fetch data from [MASK] online web sources, cleanse it and [MASK] APIs on top of it.\n",
    "Work with [MASK] databases (MongoDB) to store raw/document-based data.\n",
    "Develop a deep [MASK] of our vast data sources on the web and know exactly how, when, and which data to scrape, parse and store.\n",
    "Develop [MASK] for automating and maintaining a [MASK] flow of data from multiple sources.\n",
    "Work independently with little supervision to research and test [MASK] solutions.\n",
    "What you will need\n",
    "Strong coding [MASK] in Python and [MASK] Web Framework.\n",
    "Information retrieval â€“ Web [MASK].\n",
    "Experience with NoSQL data storage like [MASK].\n",
    "Good knowledge of Asynchronous task [MASK] like Celery.\n",
    "Experience working with large scale [MASK] and storage.\n",
    "Knowledge of [MASK] with Node.js is a plus.\n",
    "Knowledge of [MASK] with various front end technologies and how various websites are built.\n",
    "Sound [MASK] of Asynchronous Programming in python like AsyncIO.\"\"\"\n",
    "# para = para.replace('\\n', ' ')\n",
    "toks = tokenizer.encode(f'[CLS] {para} [SEP]')\n",
    "toks = torch.tensor([toks.ids]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c7c99f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = transformer_model(toks)\n",
    "output = output.argmax(dim=-1)[0].cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "dce278b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'samarit requirements : python / software engineer educational qualifications : b . c / m . net / ms / office experience : 3 0 9 years what you will do apply your skill set to interrogate data from all online web sources , cleanse it and other apis on top of it . work with relational databases ( mongodb ) to store management / document data based data . develop a deep understanding of our latest data sources on the web and know exactly how , when , and which data to scrape , parse and store . develop solutions for automating and maintaining a smooth flow of data from multiple sources . work independently with little supervision to research and test of solutions . what you will need strong coding skills in python and a web framework . information retrieval â€“ web applications . experience with nosql data storage like technologies . good knowledge of asynchronous task . likeegy . experience working with large scale , and storage . knowledge of working with node . js is a plus . knowledge of working with various front end technologies and how various websites are built . sound knowledge of asynchronous programming in python like a ao . .'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(output.numpy()).replace(' ##', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "af3a1257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df.FullDescription.str.contains('data science')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bf1bd700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Location  Leeds. My client, an established and growing IT company are currently recruiting for a Telemarketing Executive. This is an exciting new business sales opportunity to join a forward thinking organisation that continues to go from strength to strength. The Telemarketing Executive role offers an excellent platform for progression to Senior Account Manager. Role Profile: The Telemarketer function is a key position to feed the growth objectives of the organisation. The intention of this position is to drive new clients to a Workshop and/or contact new clients on a range of specific products and service offerings on a project by project basis. The position is a training ground to further graduate onto junior account manager role after approximately ****2 months. It is expected that you will be capable of using the phone and email to convey value of the workshop or project with a qualified decision maker. Key Responsibilities: Your main targets will include: Ability to make **** outbound calls per day To speak with a minimum of 10 decision maker contacts To meet specific project targets E.g. workshop **** delegate per day To meet a minimum of 1 hour call each day Product, industry and service knowledge goals Your consultative style and proactivity will enable you to understand customers business, identify their needs and then leverage this information to achieve the required goal.'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.FullDescription[5500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bef5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40c70ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.memory_summary(device=None, abbreviated=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "757ee114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "# del rnn_mlm_model\n",
    "# del optimizer\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8615d6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f81ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.view(-1, output.shape[-1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5beff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d961dfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = rnn_mlm_model(batch['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7ec39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_loss = 0.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p36",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
